%=============================================================
\section{Introduction}
%=============================================================


Every security mechanism hides a distributional question that its designers rarely ask
explicitly: \emph{who pays?} The performance tax from speculative execution mitigations
fell almost entirely on cloud operators and datacenter owners who had no role in the
original microarchitectural design decisions~\cite{kocher2019spectre,koruyeh2022retbleed}.
The integration burden from capability-based memory safety falls on software
ecosystems that must retrofit decades of existing code~\cite{woodruff2014cheri}.
The compliance overhead from trusted boot and firmware resilience requirements falls
on OEMs navigating certification timelines they did not set~\cite{cooper2018sp800193}.
In each case, the actor who chose the mechanism, the actor who paid for it, and the
actor who received its protection are three different parties.

This is not an occasional anomaly. It is the normal condition of hardware and systems
security. Security mechanisms are evaluated, selected, and deployed within one
organizational context while their costs materialize---sometimes years later---in
another. Yet the tools available for analyzing this situation are poorly matched to it.
The result is a persistent \emph{fog of war} around security costs: decisions are made
under allocation opacity, burden pathways are implicit rather than explicit, and the
question of who bears which costs is rarely part of the formal decision record.

Two research traditions have been circling this problem without quite converging on it.

\paragraph{The systems engineering tradition} has developed precise methods for
characterizing the costs of security mechanisms in terms of power, performance, and
area (PPA), as well as engineering labor, verification effort, and schedule impact. This
tradition understands that every design choice is a point in a multidimensional tradeoff
space, that constraints interact, and that opportunity costs are real: die area committed
to a hardware security feature is die area unavailable for compute, memory bandwidth,
or energy efficiency. Hardware architects think in these terms habitually. The tradeoff
space is their natural habitat.

What this tradition typically does not model is \emph{where} costs land. A published
evaluation of a trusted execution environment reports gate-count overhead and
performance impact on representative workloads~\cite{costan2016sanctum,tsai2017graphenesgx}.
It does not report who bears the integration cost when an OEM must certify a new
firmware stack, or who absorbs the operational cost when a cloud provider must
maintain multiple TEE generations across a heterogeneous fleet. Distribution is
treated as outside the scope of mechanism evaluation.

\paragraph{The security economics tradition} has developed equally precise methods
for characterizing the distributional consequences of security decisions: externalities,
principal-agent misalignment, information asymmetry, and the systematic ways that
individually rational decisions produce collectively suboptimal outcomes~\cite{anderson2001why,anderson2006economics}.
This tradition understands that the actor who chooses a security control is often not
the actor who pays for it, and that this misalignment produces predictable
underinvestment, cost-shifting, and accountability gaps.

What this tradition typically does not model is \emph{how} mechanism-level technical
choices produce specific distributions. The mechanism is treated as a black box: it
either exists or does not, is adopted or is not. The question of why speculative
execution controls concentrate recurring burden on cloud operators while memory
safety mitigations concentrate upfront burden on toolchain integrators---questions
whose answers are embedded in specific technical properties of the mechanisms
themselves---is not something the economics toolkit is equipped to answer.

\paragraph{The gap.} Neither tradition, alone, can trace burden pathways \emph{through}
the mechanism. The engineering toolkit explains what a mechanism costs but not where
those costs go. The economics toolkit explains where costs end up but not why specific
technical choices produce specific distributions rather than others. Together, they
describe the same phenomenon from complementary angles. What is missing is the
translation layer that makes them commensurable.

\paragraph{This paper.} We propose a synthesis organized around a central reframing:
\emph{hardware security mechanisms should be understood as burden-allocation
instruments}---devices that distribute security costs, risks, and residual liabilities
across stakeholders, organizations, and timescales. This framing is not a replacement
for either tradition. It is the joint lens that puts them in productive contact.

The synthesis has three components. First, a conceptual argument: we show that the
engineering concept of a design tradeoff and the economic concept of a cost externality
are descriptions of the same underlying phenomenon, and that recognizing this
equivalence changes what questions we ask about mechanism selection. Second, a
shared vocabulary: grounded in two case studies, we develop the minimum set of
concepts needed to trace burden pathways through technical mechanisms---concepts
that map engineering terms onto economic terms and make the translation explicit.
Third, a demonstration: we show that the combined framework reveals things that
neither tradition could see alone, specifically, that mechanism properties \emph{determine}
burden distributions prospectively, not merely retrospectively, and that this has
concrete implications for mechanism evaluation, procurement, and disclosure.

We ground the argument in two case studies chosen to complement each other. The
first---speculative execution controls---provides a deep analysis of a single mechanism
family in which the burden pathway is historically documented and consequential. The
second---memory safety mechanisms---provides a comparative analysis across four
technically distinct approaches to the same security objective, stress-testing the
vocabulary against mechanisms with sharply different burden pathway signatures.
Together, the case studies show both that the framework is analytically productive and
that it generalizes across the diversity of hardware and systems security practice.

\paragraph{Contributions.} This paper makes four contributions:
\begin{itemize}
  \item A central reframing of hardware security mechanisms as burden-allocation
    instruments, synthesizing systems engineering and security economics around a
    shared unit of analysis.
  \item An analysis of the structural gap between these two traditions and a diagnosis
    of why allocation opacity persists despite both traditions' sophistication.
  \item A shared vocabulary---developed inductively from case studies rather than
    imposed from above---that makes burden pathways explicit and comparable across
    mechanisms and stakeholders.
  \item Two grounded case studies demonstrating that the synthesis reveals mechanism
    properties that determine burden distributions prospectively, with implications for
    evaluation, procurement, and policy.
\end{itemize}

\paragraph{Scope and non-goals.} Our focus is hardware and systems security
mechanisms: microarchitectural controls, trusted execution environments, memory
safety hardware, and related platform security features. We do not attempt a full
treatment of software-only security economics, geopolitical supply-chain externalities,
or game-theoretic attacker modeling. These are important topics but orthogonal to the
core synthesis we develop here.

The remainder of the paper proceeds as follows. Section~\ref{sec:traditions} develops
the two-traditions framing in detail and identifies the specific gap that the synthesis
addresses. Sections~\ref{sec:spectre} and~\ref{sec:memsafety} present the two case
studies. Section~\ref{sec:vocabulary} crystallizes the shared vocabulary that the case
studies reveal as necessary. Section~\ref{sec:synthesis} draws out what the combined
framework reveals. Section~\ref{sec:limitations} addresses limitations and future work,
and Section~\ref{sec:conclusion} concludes.